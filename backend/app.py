from fastapi import FastAPI, UploadFile, File, Query
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import shutil
import cv2
import os
import uuid
import json
import pandas as pd
import numpy as np
from deepface import DeepFace
from sklearn.metrics.pairwise import cosine_similarity
import ast
import re

# =========================
# åˆæœŸåŒ–
# =========================
app = FastAPI()
UPLOAD_FOLDER = "uploads"  # Cloud Run ãªã‚‰ "/tmp" ã‚’æ¨å¥¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# CORSï¼ˆãƒ•ãƒ­ãƒ³ãƒˆ: 3000 ã‚’è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def norm_name(s: str) -> str:
    """åå‰ã®è¡¨è¨˜æºã‚Œã‚’å¸åï¼ˆç©ºç™½å…¨å‰Šé™¤ï¼‰"""
    return re.sub(r"\s+", "", s or "")

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
# ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’ã€Œæ­£è¦åŒ–ã—ãŸnameã€ã§å¼•ã‘ã‚‹è¾æ›¸ã«ã™ã‚‹
MEMBERS_JSON = "member_data_final_cleaned.json"
with open(MEMBERS_JSON, encoding="utf-8") as f:
    members_raw = json.load(f)

name_to_member = {}
for k, info in members_raw.items():
    nm = info.get("name", "")
    key = norm_name(nm)
    # é‡è¤‡ã¯æœ€åˆã®1ä»¶ã‚’æ¡ç”¨ï¼ˆå¿…è¦ãªã‚‰ã“ã“ã‚’ä¸Šæ›¸ãã«å¤‰ãˆã¦OKï¼‰
    if key and key not in name_to_member:
        name_to_member[key] = {
            "name": info.get("name", ""),
            "group": info.get("group", ""),
            "image": info.get("image", "") or info.get("imageUrl", ""),
            "profileUrl": info.get("profileUrl", ""),
            "goods": info.get("goods", {}) or info.get("goodsLinks", {}),
        }

# ç‰¹å¾´é‡CSVï¼ˆåˆ—: name, featuresï¼‰
FEATURES_CSV = "member_features_vggface_direct_ver1.1.csv"
df_features = pd.read_csv(FEATURES_CSV)

# å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
if "features" not in df_features.columns or "name" not in df_features.columns:
    raise ValueError("CSVã« 'name' ã¾ãŸã¯ 'features' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# "features"ï¼ˆ"[0.1, 0.2, ...]"ï¼‰â†’ np.array(4096,)
df_features["features"] = df_features["features"].apply(
    lambda s: np.array(ast.literal_eval(s), dtype=np.float32)
)

# 4096æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
if not df_features["features"].apply(lambda v: isinstance(v, np.ndarray) and v.shape == (4096,)).all():
    raise ValueError("featuresåˆ—ã®æ¬¡å…ƒãŒ4096ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚CSVã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# æ­£è¦åŒ–ååˆ—ï¼ˆçªåˆã›ç”¨ï¼‰
df_features["name_norm"] = df_features["name"].astype(str).apply(norm_name)

# é¡ä¼¼åº¦è¨ˆç®—ã®ãŸã‚ã®ã¾ã¨ã‚
name_list = df_features["name"].tolist()
member_matrix = np.stack(df_features["features"].to_numpy(), axis=0)  # (N,4096)

# åå‰â†’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«è¾æ›¸ï¼ˆ/diagnose ç”¨ï¼‰
feature_dict = dict(zip(df_features["name"], df_features["features"]))

# =========================
# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =========================
class DiagnoseRequest(BaseModel):
    filename: str  # â€»äº’æ›ã®ãŸã‚ãã®ã¾ã¾ã€‚å®Ÿéš›ã¯ "name"ï¼ˆãƒ¡ãƒ³ãƒãƒ¼åï¼‰ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚

@app.get("/")
def root():
    return {"ok": True, "service": "oshimen-ai-api"}

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/diagnose")
def diagnose(req: DiagnoseRequest):
    """ãƒ¡ãƒ³ãƒãƒ¼åã‚’å…¥åŠ›ã—ã¦ä¸Šä½ã®ä¼¼ã¦ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã‚’è¿”ã™ï¼ˆè‡ªå·±è¨ºæ–­ç”¨ï¼‰"""
    query_name = req.filename
    if query_name not in feature_dict:
        return {"error": f"{query_name} not found in features."}

    query_vector = feature_dict[query_name].reshape(1, -1)
    sims = cosine_similarity(query_vector, member_matrix)[0]

    # è‡ªåˆ†è‡ªèº«ã‚’é™¤å¤–ã—ã¦ä¸Šä½10
    similarities = []
    for i, nm in enumerate(name_list):
        if nm == query_name:
            continue
        similarities.append((nm, float(sims[i])))

    top_matches = sorted(similarities, key=lambda x: x[1], reverse=True)[:10]

    results = []
    for nm, score in top_matches:
        info = name_to_member.get(norm_name(nm), {"name": nm, "group": "", "image": "", "profileUrl": "", "goods": {}})
        results.append({
            "name": info.get("name", nm),
            "image": info.get("image", ""),
            "group": info.get("group", ""),
            "profileUrl": info.get("profileUrl", ""),
            "goods": info.get("goods", {}),
            "similarity_score": round(float(score), 4),
        })
    return {"results": results}

# é¡”åˆ‡ã‚Šå‡ºã—ï¼ˆDeepFace.extract_faces ã‚’ä½¿ç”¨ï¼‰
def process_face(image_path, output_path, target_size=(160, 160)):
    try:
        faces = DeepFace.extract_faces(
            image_path,
            detector_backend="opencv",
            enforce_detection=False
        )
        print(f"âœ… extract_faces çµæœ: {faces}")
        if not faces:
            print(f"âŒ é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {image_path}")
            return None

        face = (faces[0]["face"] * 255).astype(np.uint8)  # 0-255 ã«æˆ»ã™
        h, w, _ = face.shape
        max_dim = max(h, w)
        padded = np.ones((max_dim, max_dim, 3), dtype=np.uint8) * 255
        sx = (max_dim - w) // 2
        sy = (max_dim - h) // 2
        padded[sy:sy + h, sx:sx + w] = face
        resized = cv2.resize(padded, target_size)
        Image.fromarray(resized).save(output_path)
        return output_path
    except Exception as e:
        print(f"ğŸ’¥ é¡”å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@app.post("/analyze")
async def analyze(image: UploadFile = File(...)):
    # 1) ç”»åƒä¿å­˜
    ext = os.path.splitext(image.filename)[1] or ".jpg"
    filename = f"{uuid.uuid4().hex}{ext}"
    save_path = os.path.join(UPLOAD_FOLDER, filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(image.file, buffer)

    # 2) é¡”æŠ½å‡ºãƒ»ãƒªã‚µã‚¤ã‚º
    cropped_path = os.path.join(UPLOAD_FOLDER, f"cropped_{filename}")
    result = process_face(save_path, cropped_path)
    if result is None:
        try:
            os.remove(save_path)
        except Exception:
            pass
        return {"error": "é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ"}

    # 3) åŸ‹ã‚è¾¼ã¿æŠ½å‡ºï¼ˆVGG-Faceï¼‰
    try:
        rep = DeepFace.represent(
            img_path=cropped_path,
            model_name="VGG-Face",
            detector_backend="skip",
            enforce_detection=False
        )
        embedding = rep[0]["embedding"]
    except Exception as e:
        try:
            os.remove(save_path); os.remove(cropped_path)
        except Exception:
            pass
        return {"error": "ç‰¹å¾´æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ", "details": str(e)}

    # 4) ãƒ¦ãƒ¼ã‚¶ãƒ™ã‚¯ãƒˆãƒ«æ•´å½¢ & é¡ä¼¼åº¦
    user_vec = np.array(embedding, dtype=np.float32)
    if user_vec.shape != (4096,):
        try:
            os.remove(save_path); os.remove(cropped_path)
        except Exception:
            pass
        return {"error": f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒãŒæƒ³å®šå¤–ã§ã™: got {user_vec.shape}"}

    user_vec = user_vec.reshape(1, -1)  # (1,4096)
    user_vec = np.nan_to_num(user_vec, copy=False)

    sims = cosine_similarity(user_vec, member_matrix)[0]  # (N,)

    # DataFrameåŒ–ã—ã¦ä¸Šä½ã‚’æŠ½å‡ºï¼ˆnameé‡è¤‡é™¤å» â†’ ä¸Šä½3ï¼‰
    df_sorted = pd.DataFrame({
        "name": name_list,
        "similarity_score": sims.astype(float),
    }).sort_values("similarity_score", ascending=False)

    df_unique = df_sorted.drop_duplicates(subset=["name"]).head(3)

    # 5) ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ä»˜ä¸ï¼ˆscoreã¯è¿”ã•ãªã„ä»•æ§˜ï¼‰
    results = []
    for _, row in df_unique.iterrows():
        nm = row["name"]
        info = name_to_member.get(norm_name(nm), {"name": nm, "group": "", "image": "", "profileUrl": "", "goods": {}})
        results.append({
            "image_name": nm,  # äº’æ›ç”¨
            "name": info.get("name", nm),
            "group": info.get("group", ""),
            "imageUrl": info.get("image", ""),
            "profileUrl": info.get("profileUrl", ""),
            "goods": info.get("goods", {}),
            # "similarity_score": round(float(row["similarity_score"]), 4),
        })

    # 6) å¾Œå§‹æœ«
    try:
        os.remove(save_path)
        os.remove(cropped_path)
    except Exception as e:
        print(f"âš  ç”»åƒå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

    return {"results": results}

# =========================
# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼ˆçªåˆã›å¯è¦–åŒ–ï¼‰
# =========================
@app.get("/debug/check-data")
def check_data(limit: int = Query(20, ge=1, le=200)):
    """CSV ã¨ JSON ã®åå‰çªåˆã›ã‚µãƒãƒª"""
    json_names = {norm_name(v.get("name", "")): v.get("name", "") for v in members_raw.values()}
    csv_names_norm = df_features["name_norm"].tolist()

    csv_not_in_json = [df_features.loc[i, "name"] for i, n in enumerate(csv_names_norm) if n not in json_names]
    json_not_in_csv = [v for k, v in json_names.items() if k not in set(csv_names_norm)]

    return {
        "csv_total": len(csv_names_norm),
        "json_total": len(json_names),
        "csv_not_in_json_count": len(csv_not_in_json),
        "json_not_in_csv_count": len(json_not_in_csv),
        "csv_not_in_json_sample": csv_not_in_json[:limit],
        "json_not_in_csv_sample": json_not_in_csv[:limit],
    }

@app.get("/debug/lookup")
def debug_lookup(name: str):
    """ç‰¹å®šã®è¡¨ç¤ºåãŒ JSON ã«ãƒ’ãƒƒãƒˆã™ã‚‹ã‹ç¢ºèª"""
    key = norm_name(name)
    hit = name_to_member.get(key)
    return {
        "query": name,
        "normalized": key,
        "found_in_json": bool(hit),
        "json_record": hit or {}
    }
